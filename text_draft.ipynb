{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en\n",
    "!pip install --no-cache-dir wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from datascience import *\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/islandpoetry1_22.txt', \"r\") as f:\n",
    "    raw = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud().generate(raw)\n",
    "\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# lower max_font_size\n",
    "wordcloud = WordCloud(max_font_size=40).generate(raw)\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# formal analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raw.split(\"\\n\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(p) for p in raw.split(\"\\n\\n\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([len(p) for p in raw.split(\"\\n\\n\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "poems = raw.split(\"\\n\\n\")\n",
    "\n",
    "all_poems_enjambment = []\n",
    "for p in poems:\n",
    "    lines = p.split(\"\\n\")\n",
    "    enjambment = 0\n",
    "    for l in lines:\n",
    "        try:\n",
    "            if l[-1] in punctuation:\n",
    "                pass\n",
    "            else:\n",
    "                enjambment += 1\n",
    "        except:\n",
    "            pass\n",
    "    enj = enjambment/len(lines)\n",
    "    all_poems_enjambment.append(enj)\n",
    "    \n",
    "print(np.mean(all_poems_enjambment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', parser=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_text = nlp(raw.replace(\"\\n\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toks_tab = Table()\n",
    "toks_tab.append_column(label=\"Word\", values=[word.text for word in parsed_text])\n",
    "toks_tab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toks_tab.append_column(label=\"POS\", values=[word.pos_ for word in parsed_text])\n",
    "toks_tab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toks_tab.where(\"POS\", are.equal_to(\"ADJ\")).group(\"Word\").sort(\"count\", descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tablefy(parsed_text):\n",
    "    toks_tab = Table()\n",
    "    toks_tab.append_column(label=\"Word\", values=[word.text for word in parsed_text])\n",
    "    toks_tab.append_column(label=\"POS\", values=[word.pos_ for word in parsed_text])\n",
    "    toks_tab.append_column(label=\"Lemma\", values=[word.lemma_ for word in parsed_text])\n",
    "    toks_tab.append_column(label=\"Stop Word\", values=[word.is_stop for word in parsed_text])\n",
    "    toks_tab.append_column(label=\"Punctuation\", values=[word.is_punct for word in parsed_text])\n",
    "    toks_tab.append_column(label=\"Space\", values=[word.is_space for word in parsed_text])\n",
    "    toks_tab.append_column(label=\"Number\", values=[word.like_num for word in parsed_text])\n",
    "    toks_tab.append_column(label=\"OOV\", values=[word.is_oov for word in parsed_text])\n",
    "    toks_tab.append_column(label=\"Dependency\", values=[word.dep_ for word in parsed_text])\n",
    "    return toks_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablefy(parsed_text).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablefy(parsed_text).where(\"Stop Word\", are.equal_to(False)).where(\"Punctuation\", are.equal_to(False)).group(\"Word\").sort(\"count\",descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablefy(parsed_text).where(\"Stop Word\", are.equal_to(False)).where(\"Punctuation\", are.equal_to(False)).where(\"Space\", are.equal_to(False)).group(\"Lemma\").sort(\"count\",descending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tab = Table()\n",
    "ner_tab.append_column(label=\"NER Label\", values=[ent.label_ for ent in parsed_text.ents])\n",
    "ner_tab.append_column(label=\"NER Text\", values=[ent.text for ent in parsed_text.ents])\n",
    "ner_tab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tab.where(\"NER Label\", are.equal_to(\"GPE\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tab.where(\"NER Label\", are.equal_to(\"GPE\")).to_df()['NER Text'].value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tab.where(\"NER Label\", are.equal_to(\"PERSON\")).to_df()['NER Text'].value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tab.where(\"NER Label\", are.equal_to(\"ORG\")).to_df()['NER Text'].value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tab.where(\"NER Label\", are.equal_to(\"DATE\")).to_df()['NER Text'].value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tab.where(\"NER Label\", are.equal_to(\"TIME\")).to_df()['NER Text'].value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
